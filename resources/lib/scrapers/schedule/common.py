# -*- coding: utf-8 -*-

import urllib.request
import os
import html
import unicodedata
import json
import gzip
import io
from bs4 import BeautifulSoup

from resources.lib.common import Common
from resources.lib.db import ThreadLocal


class Common(Common):

    SOURCE_PATH = os.path.join(Common.PROFILE_PATH, 'schedule', 'source')
    JSON_PATH = os.path.join(Common.PROFILE_PATH, 'schedule', 'json')
    
    def __init__(self, protocol):
        # DB„ÅÆÂÖ±Êúâ„Ç§„É≥„Çπ„Çø„É≥„Çπ
        self.db = ThreadLocal.db
        # „Éá„Ç£„É¨„ÇØ„Éà„É™Ë®≠ÂÆö
        self.SOURCE_FILE = os.path.join(self.SOURCE_PATH, f'{protocol}.txt')
        self.JSON_FILE = os.path.join(self.JSON_PATH, f'{protocol}.json')
        os.makedirs(os.path.dirname(self.SOURCE_FILE), exist_ok=True)
        os.makedirs(os.path.dirname(self.JSON_FILE), exist_ok=True)

    # „Éï„Ç°„Ç§„É´„Çí„Éë„Éº„Çπ„Åô„Çã
    def parse(self, data):
        # to be overwritten
        return []

    # ‰∏ÄÈÄ£„ÅÆÂá¶ÁêÜ„ÇíÂÆüË°å„Åô„Çã
    def update(self):
        # DB„Å∏ÊåøÂÖ•„Åô„ÇãÁï™ÁµÑÊÉÖÂ†±„ÅÆÊï∞„ÇíÂàùÊúüÂåñ
        count = 0
        # Áï™ÁµÑË°®ÊÉÖÂ†±„ÇíÂèñÂæó
        try:
            if self.URL:
                # HTTP„É™„ÇØ„Ç®„Çπ„Éà
                req = urllib.request.Request(self.URL)
                res = urllib.request.urlopen(req)
                # „É¨„Çπ„Éù„É≥„Çπ„ÅågzipÂúßÁ∏Æ„Åï„Çå„Å¶„ÅÑ„Çã„Å®„Åç„ÅØÂ±ïÈñã„Åô„Çã
                if res.info().get('Content-Encoding') == 'gzip':
                    with gzip.GzipFile(fileobj=io.BytesIO(res.read())) as gz:
                        data = gz.read()
                else:
                    data = res.read()
            else:
                data = b''
        except urllib.error.HTTPError as e:
            self.log(f'request error (code={e.code}):', self.URL)
            return -1 if e.code == 404 else 0
        except Exception as e:
            self.log(f'request error:', self.URL)
            self.log(e)
            return 0
        # „ÇΩ„Éº„Çπ„Çí„Éï„Ç°„Ç§„É´„Å´‰øùÂ≠ò
        with open(self.SOURCE_FILE, 'wb') as f:
            f.write(data)
        # „Éë„Éº„Çπ„Åó„Å¶Áï™ÁµÑË°®ÊÉÖÂ†±„ÇíÊäΩÂá∫
        try:
            buf = self.parse(data.decode('utf-8'))
        except Exception as e:
            self.log(f'parse error:', self.URL)
            self.log(e)
            return 0
        # Áï™ÁµÑÊÉÖÂ†±„Åå0„ÅÆÂ†¥Âêà„ÅØ„Ç®„É©„Éº„Å®„Åó„Å¶Êâ±„ÅÜÔºàrinsaikantoÔºâ
        if len(buf) == 0:
            return -1
        # ÊäΩÂá∫„Åó„ÅüÁï™ÁµÑÊÉÖÂ†±„ÇíDB„Å´ÊåøÂÖ•
        for item in buf:
            if self.db.add(item) > 0:
                count += 1  # DB„Å´ÊåøÂÖ•„Åï„Çå„ÅüÁï™ÁµÑÊÉÖÂ†±„Åå„ÅÇ„Çå„Å∞„Ç´„Ç¶„É≥„Éà„Ç¢„ÉÉ„Éó„Åô„Çã
        # „Éë„Éº„ÇπÁµêÊûú„Çíjson„Éï„Ç°„Ç§„É´„Å´‰øùÂ≠ò
        with open(self.JSON_FILE, 'wb') as f:
            f.write(json.dumps(buf, ensure_ascii=False, indent=4).encode('utf-8'))
        # DB„Å∏ÊåøÂÖ•„Åó„ÅüÁï™ÁµÑÊÉÖÂ†±„ÅÆÊï∞„ÇíËøî„Åô
        return count

    def search_nextaired(self):
        sql = '''SELECT c.start FROM contents AS c JOIN stations AS s ON c.sid = s.sid
        WHERE c.end > NOW() AND c.sid = :sid ORDER BY c.start LIMIT 1 OFFSET 1'''
        self.db.cursor.execute(sql, {'sid': self.sid})
        try:
            nextaired, = self.db.cursor.fetchone()
        except TypeError:
            nextaired = '1970-01-01 09:00:00'
        return nextaired
    
    search_nextaired0 = search_nextaired
    search_nextaired1 = search_nextaired

    def get_nextaired(self):
        sql = 'SELECT nextaired0, nextaired1 FROM stations WHERE sid = :sid'
        self.db.cursor.execute(sql, {'sid': self.sid})
        nextaired0, nextaired1 = self.db.cursor.fetchone()
        return nextaired0, nextaired1

    def set_nextaired0(self, hours=0):
        if hours == 0:
            nextaired0 = self.search_nextaired0()
        else:
            nextaired0 = self.now(hours=hours)
        sql = 'UPDATE stations SET nextaired0 = :nextaired0 WHERE sid = :sid'
        self.db.cursor.execute(sql, {'nextaired0': nextaired0, 'sid': self.sid})
        return nextaired0

    def set_nextaired1(self, hours=0):
        if hours == 0:
            nextaired1 = self.search_nextaired1()
        else:
            nextaired1 = self.now(hours=hours)
        sql = 'UPDATE stations SET nextaired1 = :nextaired1 WHERE sid = :sid'
        self.db.cursor.execute(sql, {'nextaired1': nextaired1, 'sid': self.sid})
        return nextaired1

    # ÊñáÂ≠óÂàó„ÇíÊ≠£Ë¶èÂåñ„Åô„Çã
    @staticmethod
    def normalize(text, unescape=False, parser=False):
        if text is None: return ''
        text = unicodedata.normalize('NFKC', text)
        if unescape:
            text = html.unescape(text)
        if parser:
            text = BeautifulSoup(text, 'html.parser').prettify()
        text = text.replace('<', 'Ôºú').replace('>', 'Ôºû')
        text = text.replace('üé§', '')  # „É¨„Éá„Ç£„Ç™„É¢„É¢
        return text.strip()


class DummyScraper(Common):
    
    def __init__(self, sid):
        # DB„ÅÆÂÖ±Êúâ„Ç§„É≥„Çπ„Çø„É≥„Çπ
        self.db = ThreadLocal.db
        self.sid = sid
        self.db.cursor.execute('SELECT station, key, region, pref, site FROM stations WHERE sid = :sid', {'sid': sid})
        self.station, self.key, self.region, self.pref, self.site = self.db.cursor.fetchone()

    def update(self):
        _, nextaired1 = self.get_nextaired()
        return 1 if nextaired1 < self.now() else 0

    def search_nextaired0(self):
        return self.now(hours=24)

    def search_nextaired1(self):
        return self.now(hours=24)
